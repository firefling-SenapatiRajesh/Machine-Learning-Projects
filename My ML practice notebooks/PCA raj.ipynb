{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4072bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf113af",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data=sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20b528b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "106           4.9          2.5           4.5          1.7   virginica\n",
       "108           6.7          2.5           5.8          1.8   virginica\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "33            5.5          4.2           1.4          0.2      setosa\n",
       "25            5.0          3.0           1.6          0.2      setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44e52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data.drop('species',axis=1),\n",
    "                                               iris_data['species'],test_size=0.2,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e745e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f99ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "def2248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.88152468, 0.97470924, 0.15721585, 0.02016367])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance=pca.explained_variance_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0193502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.88152468])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data.drop('species',axis=1),\n",
    "                                               iris_data['species'],test_size=0.2,random_state=100)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=1)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "explained_variance=pca.explained_variance_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f849b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(max_depth=2,random_state=100,n_estimators=10)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1a06d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        11\n",
      "  versicolor       0.83      0.83      0.83         6\n",
      "   virginica       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.92      0.92      0.92        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  5  1]\n",
      " [ 0  1 12]]\n",
      "Accuracy  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11a126d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.88152468 0.97470924]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        11\n",
      "  versicolor       0.83      0.83      0.83         6\n",
      "   virginica       0.92      0.92      0.92        13\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.92      0.92      0.92        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  5  1]\n",
      " [ 0  1 12]]\n",
      "Accuracy  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data.drop('species',axis=1),\n",
    "                                               iris_data['species'],test_size=0.2,random_state=100)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=2)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "explained_variance=pca.explained_variance_\n",
    "print(explained_variance)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(max_depth=2,random_state=100,n_estimators=10)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0901458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.88152468 0.97470924 0.15721585]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        11\n",
      "  versicolor       0.83      0.62      0.71         8\n",
      "   virginica       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.87      0.84      0.85        30\n",
      "weighted avg       0.87      0.87      0.86        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  5  1]\n",
      " [ 0  3 10]]\n",
      "Accuracy  0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data.drop('species',axis=1),\n",
    "                                               iris_data['species'],test_size=0.2,random_state=100)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA(n_components=3)\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "explained_variance=pca.explained_variance_\n",
    "print(explained_variance)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(max_depth=2,random_state=100,n_estimators=10)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af4c8828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.88152468 0.97470924 0.15721585 0.02016367]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        11\n",
      "  versicolor       0.83      0.50      0.62        10\n",
      "   virginica       0.62      0.89      0.73         9\n",
      "\n",
      "    accuracy                           0.80        30\n",
      "   macro avg       0.82      0.80      0.78        30\n",
      "weighted avg       0.83      0.80      0.79        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0  5  1]\n",
      " [ 0  5  8]]\n",
      "Accuracy  0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_data.drop('species',axis=1),\n",
    "                                               iris_data['species'],test_size=0.2,random_state=100)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "from sklearn.decomposition import PCA\n",
    "pca=PCA()\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "explained_variance=pca.explained_variance_\n",
    "print(explained_variance)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(max_depth=2,random_state=100,n_estimators=10)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred=classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(classification_report(y_pred,y_test))\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print('Accuracy ' ,  accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966305f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
